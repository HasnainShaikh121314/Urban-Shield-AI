{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "895715b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff84040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Dataset path: datasets/latest_flood_dataset.csv\n",
      "üìÅ Model directory: models\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Set paths and configuration\n",
    "csv_path = \"datasets/latest_flood_dataset.csv\"\n",
    "model_dir = \"models\"\n",
    "\n",
    "# Create model directory if it doesn't exist\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Dataset path: {csv_path}\")\n",
    "print(f\"üìÅ Model directory: {model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accc0473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading dataset...\n",
      "‚úÖ Dataset loaded: 167,637 records\n",
      "üìä Shape: (167637, 47)\n",
      "\n",
      "üìä Dataset Overview:\n",
      "   Cities: 51\n",
      "   Date range: 2015-01-01 00:00:00 to 2023-12-31 00:00:00\n",
      "   Flood events: 4,795 (2.86%)\n",
      "\n",
      "üëÄ First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>rain</th>\n",
       "      <th>rain_3day</th>\n",
       "      <th>...</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>is_pre_monsoon</th>\n",
       "      <th>is_post_monsoon</th>\n",
       "      <th>rain_7day_vs_30day</th>\n",
       "      <th>geographic_region</th>\n",
       "      <th>monsoon_rain_7day</th>\n",
       "      <th>coastal_storm_risk</th>\n",
       "      <th>mountain_rain_risk</th>\n",
       "      <th>monthly_avg_pressure</th>\n",
       "      <th>pressure_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Abbottabad</td>\n",
       "      <td>mountain</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mountain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.137312</td>\n",
       "      <td>0.192688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>Abbottabad</td>\n",
       "      <td>mountain</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mountain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.137312</td>\n",
       "      <td>0.062688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Abbottabad</td>\n",
       "      <td>mountain</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mountain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.137312</td>\n",
       "      <td>-0.017312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>Abbottabad</td>\n",
       "      <td>mountain</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mountain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.137312</td>\n",
       "      <td>0.282688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>Abbottabad</td>\n",
       "      <td>mountain</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mountain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.137312</td>\n",
       "      <td>0.142688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        city    region   country  year  month  season  \\\n",
       "0 2015-01-01  Abbottabad  mountain  Pakistan  2015      1  winter   \n",
       "1 2015-01-02  Abbottabad  mountain  Pakistan  2015      1  winter   \n",
       "2 2015-01-03  Abbottabad  mountain  Pakistan  2015      1  winter   \n",
       "3 2015-01-04  Abbottabad  mountain  Pakistan  2015      1  winter   \n",
       "4 2015-01-05  Abbottabad  mountain  Pakistan  2015      1  winter   \n",
       "\n",
       "   day_of_year  rain  rain_3day  ...  week_of_year  is_pre_monsoon  \\\n",
       "0            1   0.0        0.0  ...             1               0   \n",
       "1            2   0.0        0.0  ...             1               0   \n",
       "2            3   0.0        0.0  ...             1               0   \n",
       "3            4   0.0        0.0  ...             1               0   \n",
       "4            5   0.0        0.0  ...             2               0   \n",
       "\n",
       "   is_post_monsoon  rain_7day_vs_30day  geographic_region  monsoon_rain_7day  \\\n",
       "0                0                 0.0           mountain                0.0   \n",
       "1                0                 0.0           mountain                0.0   \n",
       "2                0                 0.0           mountain                0.0   \n",
       "3                0                 0.0           mountain                0.0   \n",
       "4                0                 0.0           mountain                0.0   \n",
       "\n",
       "   coastal_storm_risk  mountain_rain_risk  monthly_avg_pressure  \\\n",
       "0                   0                   0             90.137312   \n",
       "1                   0                   0             90.137312   \n",
       "2                   0                   0             90.137312   \n",
       "3                   0                   0             90.137312   \n",
       "4                   0                   0             90.137312   \n",
       "\n",
       "   pressure_anomaly  \n",
       "0          0.192688  \n",
       "1          0.062688  \n",
       "2         -0.017312  \n",
       "3          0.282688  \n",
       "4          0.142688  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 3: Load the dataset\n",
    "print(\"üìÇ Loading dataset...\")\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "    print(f\"‚ùå Dataset not found at {csv_path}\")\n",
    "    print(\"Please run create_validated_data.py first\")\n",
    "else:\n",
    "    df = pd.read_csv(csv_path, parse_dates=['date'] if 'date' in pd.read_csv(csv_path, nrows=1).columns else None)\n",
    "    print(f\"‚úÖ Dataset loaded: {len(df):,} records\")\n",
    "    print(f\"üìä Shape: {df.shape}\")\n",
    "    \n",
    "    # Display dataset info\n",
    "    print(f\"\\nüìä Dataset Overview:\")\n",
    "    print(f\"   Cities: {df['city'].nunique()}\")\n",
    "    if 'date' in df.columns:\n",
    "        print(f\"   Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "    print(f\"   Flood events: {df['flood_label'].sum():,} ({df['flood_label'].mean()*100:.2f}%)\")\n",
    "    \n",
    "    # Show first few rows\n",
    "    print(\"\\nüëÄ First 5 rows:\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d98ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Using 27 features for training (advanced set)\n",
      "\n",
      "üìã Features list:\n",
      "    1. rain\n",
      "    2. rain_3day\n",
      "    3. rain_7day\n",
      "    4. rain_15day\n",
      "    5. rain_30day\n",
      "    6. pressure\n",
      "    7. pressure_change\n",
      "    8. pressure_3day_trend\n",
      "    9. temp\n",
      "   10. temp_change\n",
      "   11. humidity\n",
      "   12. humidity_change\n",
      "   13. wind_speed\n",
      "   14. month\n",
      "   15. day_of_year\n",
      "   16. rain_intensity\n",
      "   17. consecutive_rain_days\n",
      "   18. heavy_rain_day\n",
      "   19. rapid_pressure_drop\n",
      "   20. pressure_anomaly\n",
      "   21. temp_3day_trend\n",
      "   22. extreme_heat\n",
      "   23. extreme_cold\n",
      "   24. high_humidity\n",
      "   25. is_monsoon_season\n",
      "   26. is_winter_rain_season\n",
      "   27. monsoon_rain_7day\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Select features for training\n",
    "\n",
    "# Base features (always include)\n",
    "base_features = [\n",
    "    'rain', 'rain_3day', 'rain_7day', 'rain_15day', 'rain_30day',\n",
    "    'pressure', 'pressure_change', 'pressure_3day_trend',\n",
    "    'temp', 'temp_change',\n",
    "    'humidity', 'humidity_change',\n",
    "    'wind_speed',\n",
    "    'month', 'day_of_year'\n",
    "]\n",
    "\n",
    "# Advanced features from feature_engineering.py\n",
    "advanced_features = [\n",
    "    'rain_intensity', 'consecutive_rain_days', 'heavy_rain_day',\n",
    "    'rapid_pressure_drop', 'pressure_anomaly',\n",
    "    'temp_3day_trend', 'extreme_heat', 'extreme_cold',\n",
    "    'high_humidity',\n",
    "    'is_monsoon_season', 'is_winter_rain_season',\n",
    "    'monsoon_rain_7day'\n",
    "]\n",
    "\n",
    "# Define feature sets\n",
    "feature_sets = {\n",
    "    'base': base_features,\n",
    "    'advanced': base_features + [f for f in advanced_features if f in df.columns],\n",
    "    'all': [col for col in df.columns if col not in \n",
    "            ['date', 'city', 'region', 'country', 'flood_label', 'flood_severity', \n",
    "             'flood_type', 'data_source', 'year', 'season', 'geographic_region']]\n",
    "}\n",
    "\n",
    "# Choose which feature set to use\n",
    "use_feature_set = 'advanced'  # Change to 'base' or 'all' if needed\n",
    "\n",
    "# Get available features\n",
    "available_features = [col for col in feature_sets[use_feature_set] if col in df.columns]\n",
    "\n",
    "print(f\"üîß Using {len(available_features)} features for training ({use_feature_set} set)\")\n",
    "print(\"\\nüìã Features list:\")\n",
    "for i, feature in enumerate(available_features, 1):\n",
    "    print(f\"   {i:2d}. {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2470ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öñÔ∏è Class balance: 2.86% positive (flood) samples\n",
      "   Class 0 (No Flood): 97.14%\n",
      "   Class 1 (Flood): 2.86%\n",
      "\n",
      "‚ö†Ô∏è Missing values detected. Filling with column means...\n",
      "‚úÖ Missing values handled\n",
      "\n",
      "üìä Feature matrix shape: (167637, 27)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Prepare X and y\n",
    "X = df[available_features]\n",
    "y = df['flood_label']\n",
    "\n",
    "# Check for class imbalance\n",
    "class_ratio = y.mean()\n",
    "print(f\"\\n‚öñÔ∏è Class balance: {class_ratio*100:.2f}% positive (flood) samples\")\n",
    "print(f\"   Class 0 (No Flood): {(1-class_ratio)*100:.2f}%\")\n",
    "print(f\"   Class 1 (Flood): {class_ratio*100:.2f}%\")\n",
    "\n",
    "# Handle any missing values\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(\"\\n‚ö†Ô∏è Missing values detected. Filling with column means...\")\n",
    "    X = X.fillna(X.mean())\n",
    "    print(\"‚úÖ Missing values handled\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No missing values found\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=available_features)\n",
    "\n",
    "print(f\"\\nüìä Feature matrix shape: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0de751be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Data Split:\n",
      "   Training set: 134,109 samples (80.0%)\n",
      "   Test set: 33,528 samples (20.0%)\n",
      "   Training flood events: 3,836 (2.86%)\n",
      "   Test flood events: 959 (2.86%)\n",
      "\n",
      "‚öñÔ∏è Class weights: {np.int64(0): np.float64(0.5147229280050356), np.int64(1): np.float64(17.48031803962461)}\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Split data with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Data Split:\")\n",
    "print(f\"   Training set: {len(X_train):,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Test set: {len(X_test):,} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Training flood events: {y_train.sum():,} ({y_train.mean()*100:.2f}%)\")\n",
    "print(f\"   Test flood events: {y_test.sum():,} ({y_test.mean()*100:.2f}%)\")\n",
    "\n",
    "# Compute class weights for imbalanced data\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "print(f\"\\n‚öñÔ∏è Class weights: {class_weight_dict}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0f862c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üå≤ Training Random Forest Model...\n",
      "======================================================================\n",
      "‚úÖ Random Forest training complete!\n",
      "\n",
      "üìä Random Forest Results:\n",
      "   Training accuracy: 0.9902\n",
      "   Test accuracy: 0.9883\n",
      "   ROC-AUC score: 0.9981\n",
      "   F1 Score: 0.8269\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Train Random Forest Classifier\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üå≤ Training Random Forest Model...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"‚úÖ Random Forest training complete!\")\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_train_score = rf_model.score(X_train, y_train)\n",
    "rf_test_score = rf_model.score(X_test, y_test)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "rf_auc = roc_auc_score(y_test, rf_proba)\n",
    "rf_f1 = f1_score(y_test, rf_pred)\n",
    "\n",
    "print(f\"\\nüìä Random Forest Results:\")\n",
    "print(f\"   Training accuracy: {rf_train_score:.4f}\")\n",
    "print(f\"   Test accuracy: {rf_test_score:.4f}\")\n",
    "print(f\"   ROC-AUC score: {rf_auc:.4f}\")\n",
    "print(f\"   F1 Score: {rf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2637b7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ Training Gradient Boosting Model...\n",
      "======================================================================\n",
      "‚úÖ Gradient Boosting training complete!\n",
      "\n",
      "üìä Gradient Boosting Results:\n",
      "   Training accuracy: 0.9996\n",
      "   Test accuracy: 0.9978\n",
      "   ROC-AUC score: 0.9992\n",
      "   F1 Score: 0.9608\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Train Gradient Boosting Classifier\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ Training Gradient Boosting Model...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit(X_train, y_train)\n",
    "print(\"‚úÖ Gradient Boosting training complete!\")\n",
    "\n",
    "# Evaluate Gradient Boosting\n",
    "gb_train_score = gb_model.score(X_train, y_train)\n",
    "gb_test_score = gb_model.score(X_test, y_test)\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "gb_proba = gb_model.predict_proba(X_test)[:, 1]\n",
    "gb_auc = roc_auc_score(y_test, gb_proba)\n",
    "gb_f1 = f1_score(y_test, gb_pred)\n",
    "\n",
    "print(f\"\\nüìä Gradient Boosting Results:\")\n",
    "print(f\"   Training accuracy: {gb_train_score:.4f}\")\n",
    "print(f\"   Test accuracy: {gb_test_score:.4f}\")\n",
    "print(f\"   ROC-AUC score: {gb_auc:.4f}\")\n",
    "print(f\"   F1 Score: {gb_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126219d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1786203847.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Hasnain\\AppData\\Local\\Temp\\ipykernel_9400\\1786203847.py\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    }\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Train XGBoost (if available)\n",
    "try:\n",
    "    \n",
    "    # Train the model\n",
    "    \n",
    "    # Evaluate XGBoost\n",
    "    \n",
    "    # Store models for comparison\n",
    "    models = {\n",
    "        'RandomForest': rf_model,\n",
    "        'GradientBoosting': gb_model,\n",
    "        \n",
    "    }\n",
    "    \n",
    "    results = {\n",
    "        'RandomForest': {'train_acc': rf_train_score, 'test_acc': rf_test_score, 'auc': rf_auc, 'f1': rf_f1},\n",
    "        'GradientBoosting': {'train_acc': gb_train_score, 'test_acc': gb_test_score, 'auc': gb_auc, 'f1': gb_f1},\n",
    "        \n",
    "    }\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è XGBoost not installed. Using only Random Forest and Gradient Boosting.\")\n",
    "    models = {\n",
    "        'RandomForest': rf_model,\n",
    "        'GradientBoosting': gb_model\n",
    "    }\n",
    "    \n",
    "    results = {\n",
    "        'RandomForest': {'train_acc': rf_train_score, 'test_acc': rf_test_score, 'auc': rf_auc, 'f1': rf_f1},\n",
    "        'GradientBoosting': {'train_acc': gb_train_score, 'test_acc': gb_test_score, 'auc': gb_auc, 'f1': gb_f1}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b68ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700dafdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "floodguard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
